{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a705466-d405-465d-96a9-745fa987f581",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "##  Agenda\n",
    "- Introduction to ensemble learning\n",
    "    * Goals of ensemble learning\n",
    "    * Importance of ensemble learning\n",
    "    * Weak and Strong learners in Ensemble learning\n",
    "- Categories in ensemble learning\n",
    "    * Sequential ensemble technique\n",
    "    * Parallel ensemble technique\n",
    "- Simple techniques used in ensemble learning\n",
    "    * Voting\n",
    "        * Hard Voting\n",
    "        * Soft Voting\n",
    "- Advanced techniques used in ensemble learning\n",
    "    * Bagging (bootstrap aggregating)\n",
    "        * Bagging Techniques\n",
    "        * Advantages of bagging\n",
    "        * Disadvantages of bagging\n",
    "        * Out-of-bag (OOB) concept\n",
    "    * Boosting\n",
    "        * Boosting Techniques\n",
    "        * Advantages of boosting\n",
    "        * Disadvantages of boosting\n",
    "    * Stacking\n",
    "        * Advantages of stacking\n",
    "        * Disadvantages of stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45592bdf-6ae7-4050-84c1-ababf0b0a2d0",
   "metadata": {},
   "source": [
    "## __Introduction to Ensemble Learning__\n",
    "Ensemble learning combines multiple models to enhance the overall performance of machine learning algorithms. The fundamental principle of ensemble learning is combining predictions from multiple individual models to produce a more accurate and robust prediction than any single model.\n",
    "\n",
    "### __Goals of Ensemble Learning__\n",
    "- Enhance predictive accuracy by combining multiple models.\n",
    "- Improve model robustness and generalization performance.\n",
    "\n",
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_07/ensemble_learning.png)\n",
    "\n",
    "\n",
    "\n",
    "## __Importance of Ensemble Learning__\n",
    "- Improves prediction accuracy by combining diverse models\n",
    "- Enhances model resilience and robustness against uncertainties\n",
    "- Mitigates biases and errors present in individual models\n",
    "- Captures a wide range of perspectives to achieve better performance\n",
    "- Provides reliable and robust forecasts across various domains, ensuring more dependable outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216b979a-dfed-4216-ad7e-d941e86cc5d2",
   "metadata": {},
   "source": [
    "## __Weak and Strong learners in Ensemble Learning__\n",
    "- A **Weak learner** (WL) or **Base learner** is a learning algorithm\n",
    "capable of producing classifiers with probability of error strictly (but only slightly) less than that of random guessing (0.5, in the case of binary)\n",
    "- On the other hand, **Strong learner** (SL) is able (given enough training data) to yield classifiers with arbitrarily small error probability. It performs much better than random guessing.\n",
    "  \n",
    "An ensemble (or committee) of classifiers is a classifier build upon some\n",
    "combination of Weak learner. The strategy of boosting, and ensembles of classifiers, is to learn many weak classifiers and combine them, instead of trying to learn a single Strong learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc69da40-9483-4014-bc2d-37b02a610489",
   "metadata": {},
   "source": [
    "## Categories of Ensemble Learning\n",
    "\n",
    "Ensemble Learning can be broadly classified into two categories\n",
    "\n",
    "- Sequential Ensembing Techniques\n",
    "- Parallel Ensembling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86835438-e631-4c63-8300-554b986f845c",
   "metadata": {},
   "source": [
    "# Sequential Ensembling Technique\n",
    "These techniques train models sequentially, with each model attempting to correct its predecessor's errors. This technique focuses on improving the overall performance of the ensemble by iteratively refining predictions. An example of this approach is boosting.\n",
    "\n",
    "__Note:__ It typically employs weak learners as base estimators because these learners initially have higher error rates.\n",
    "\n",
    "The steps involved in the sequential ensemble technique depend on the data structure and the requirements of the application. They are:\n",
    "1. __Base Model Selection__: Choose the initial model.\n",
    "2. __Sequential Training__: Train models one after the other.\n",
    "3. __Error Correction__: Each model learns from previous mistakes.\n",
    "4. __Prediction Refinement__: Iteratively refine predictions.\n",
    "5. __Combining Predictions__: Combine predictions from all models.\n",
    "6. __Evaluation__: Assess ensemble performance using metrics.\n",
    "\n",
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_07/Sequential_Ensemble_Technique.png)\n",
    "\n",
    "__Note:__ If all four base models are of the same type, it is considered to be a homogeneous ensemble. If they are different, it is considered heterogeneous.\n",
    "\n",
    "\n",
    "The diagram above shows the training data divided into four samples, with each sample trained on a distinct base model. Insights gained from model M1 are passed to model M2 alongside sample S2. M2 then adjusts its weights and biases based on the outcomes of M1. This process repeats for models 2, 3, and 4. Finally, all the learners are combined using a weighted averaging strategy.\n",
    "The summation sign ($ ∑ $) indicates the function that adjusts the model to improve its overall performance\n",
    "\n",
    "\n",
    "__The sequential ensemble technique is employed when dealing with:__\n",
    "- Complex relationships between input features and the target variable\n",
    "- Diverse data types, including numerical, categorical, and textual data\n",
    "- Imbalanced datasets, where skewed class distributions pose classification challenges.\n",
    "- Incremental updates are needed to adapt models gradually to evolving data over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4383531-9302-4eca-810d-6b8d2e47d7a9",
   "metadata": {},
   "source": [
    "# Parallel Ensembling Techniques\n",
    "The parallel ensemble technique concurrently trains models. They combine the predictions from multiple models to improve the final output. Bagging and Random Forest algorithms are examples of parallel ensemble techniques.\n",
    "\n",
    "__Note:__  It employs stronger learners as base estimators.\n",
    "\n",
    "The steps involved in the parallel ensemble technique are:\n",
    "1. __Data Partitioning__: Divide the dataset into subsets\n",
    "2. __Model Training__: Train models concurrently on subsets\n",
    "3. __Prediction__: Models make independent predictions\n",
    "4. __Combining Predictions__: Aggregate predictions using techniques like voting or averaging\n",
    "5. __Evaluation__: Assess ensemble performance using metrics\n",
    "\n",
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_07/Parallel_Ensemble_Technique.png)\n",
    "\n",
    "In the above diagram, the training data is divided into four samples, labeled S1 to S4, each trained on a distinct base model (M1 to M4). Unlike the sequential ensemble technique, the data in the base learners is independent. This independence of base learners significantly reduces the error due to the application of averages.\n",
    "The summation sign ($ ∑ $) indicates the aggregated model with improved performance, which has been learned from all independent base models, M1 to M4.\n",
    "\n",
    "The parallel ensemble technique is used to:\n",
    "- Enhance scalability, allowing for the efficient processing of large volumes of data by distributing the workload\n",
    "- Expedite training and prediction processes through parallel computation on multi-core systems.\n",
    "- Reduce susceptibility to noise and overfitting by averaging out individual model errors.\n",
    "- Capture diverse data patterns effectively by utilizing different models trained on varied data subsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b41e8-58c1-4a97-bc4a-e32bd649f564",
   "metadata": {},
   "source": [
    "## Simple Techniques used in Ensemble Learning\n",
    "There are 2 major strategies used as simple technique in ensemble learning\n",
    "- voting -  used for classification \n",
    "- averaging - used for regression\n",
    "\n",
    "## __Voting__\n",
    "Voting is one of the fundamental methods of ensemble learning. It involves aggregating the predictions from multiple models to arrive at a final prediction.\n",
    "Two common types of voting in ensemble learning are:\n",
    "* Majority voting/Hard voting\n",
    "* Weighted voting/Soft voting.\n",
    "\n",
    "### __Majority Voting/Hard Voting__\n",
    "Majority Voting or Hard Voting is an ensemble learning classification technique. It involves multiple models, making predictions for each data point. Each model's prediction is considered a __vote__. The final prediction is determined by the majority vote among the models.\n",
    "\n",
    "__Example:__\n",
    "    \n",
    "- Majority Voting ensemble works on breast cancer classification by combining predictions from multiple individual classifiers, such as Logistic Regression, Decision Tree, and Support Vector Machine.\n",
    "- Each classifier provides its prediction for whether a given sample belongs to a certain class. The voting ensemble then aggregates these predictions using a voting mechanism.\n",
    "- The final prediction is determined based on the most commonly predicted class among all classifiers.\n",
    "- This approach leverages the collective wisdom of diverse models to improve overall prediction accuracy and robustness in breast cancer classification tasks.\n",
    "\n",
    "### __Weighted Voting/Soft Voting__\n",
    "Soft voting takes into account the probability estimates for each class provided by the models, assuming the models are capable of estimating these probabilities (i.e., they have a predict_proba method). The final prediction is determined by averaging these probabilities across all models, and the class with the highest average probability is selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba09294-9f39-4f62-9875-0c8012f7efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us implement Majority Voting/HardVoting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7165550b-9eb5-4dda-9a5f-fae5a9f07010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2bfcfb-dca3-46f5-829e-6563ef5527fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample code  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0      1000025                5                        1   \n",
       "1      1002945                5                        4   \n",
       "2      1015425                3                        1   \n",
       "3      1016277                6                        8   \n",
       "4      1017023                4                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0           1                3                1        1      2  \n",
       "1          10                3                2        1      2  \n",
       "2           2                3                1        1      2  \n",
       "3           4                3                7        1      2  \n",
       "4           1                3                1        1      2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from the specified URL and assign column names to the DataFrame\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', header=None)\n",
    "\n",
    "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "                'Normal Nucleoli', 'Mitoses', 'Class']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4654fadb-0ddd-4758-b3c2-79f6aacd1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Sample Code\n",
    "data =  data.drop(columns = ['Sample code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240d6f4c-5ad9-4449-86cc-f59af2cc848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   Clump Thickness              699 non-null    int64 \n",
      " 1   Uniformity of Cell Size      699 non-null    int64 \n",
      " 2   Uniformity of Cell Shape     699 non-null    int64 \n",
      " 3   Marginal Adhesion            699 non-null    int64 \n",
      " 4   Single Epithelial Cell Size  699 non-null    int64 \n",
      " 5   Bare Nuclei                  699 non-null    object\n",
      " 6   Bland Chromatin              699 non-null    int64 \n",
      " 7   Normal Nucleoli              699 non-null    int64 \n",
      " 8   Mitoses                      699 non-null    int64 \n",
      " 9   Class                        699 non-null    int64 \n",
      "dtypes: int64(9), object(1)\n",
      "memory usage: 54.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9fa4eb-3c02-4f0e-8195-4fc3d6f60d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '2', '4', '3', '9', '7', '?', '5', '8', '6'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for unique valuesin Bare Nuclei \n",
    "data['Bare Nuclei'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba029ca-d96a-4f3a-ad81-da6d0f69c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace `?` with 0 in Bare Nuclei \n",
    "\n",
    "data['Bare Nuclei'] =  data['Bare Nuclei'].apply(lambda x: 0 if x =='?' else int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75f85962-3085-4cfa-94d0-79fb4f3f7ae5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count  Dtype\n",
      "---  ------                       --------------  -----\n",
      " 0   Clump Thickness              699 non-null    int64\n",
      " 1   Uniformity of Cell Size      699 non-null    int64\n",
      " 2   Uniformity of Cell Shape     699 non-null    int64\n",
      " 3   Marginal Adhesion            699 non-null    int64\n",
      " 4   Single Epithelial Cell Size  699 non-null    int64\n",
      " 5   Bare Nuclei                  699 non-null    int64\n",
      " 6   Bland Chromatin              699 non-null    int64\n",
      " 7   Normal Nucleoli              699 non-null    int64\n",
      " 8   Mitoses                      699 non-null    int64\n",
      " 9   Class                        699 non-null    int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 54.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3fa3219-bd39-47ad-b0e8-5ecc62beedce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "2    458\n",
       "4    241\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Target value Distribution\n",
    "\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad06661a-99ec-4033-abca-f8ddbbb2dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the class values to be binary (2 benign , 4 malignant)\n",
    "data['Class'] =  data['Class'].replace({2:0, 4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c7e6c16-57ea-47bd-8bed-2c12259aa3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Features and target\n",
    "X =  data.iloc[:, :-1]\n",
    "y =  data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b46003a7-983e-41ce-8bff-68b9d221e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Train Test Split\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size =0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3400fb7d-691b-4245-9f94-21a2030cb18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.470483</td>\n",
       "      <td>3.139535</td>\n",
       "      <td>3.214669</td>\n",
       "      <td>2.831843</td>\n",
       "      <td>3.216458</td>\n",
       "      <td>3.431127</td>\n",
       "      <td>3.450805</td>\n",
       "      <td>2.867621</td>\n",
       "      <td>1.60644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.841469</td>\n",
       "      <td>3.060067</td>\n",
       "      <td>2.974877</td>\n",
       "      <td>2.879352</td>\n",
       "      <td>2.225950</td>\n",
       "      <td>3.632070</td>\n",
       "      <td>2.387391</td>\n",
       "      <td>3.060385</td>\n",
       "      <td>1.77569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "count       559.000000               559.000000                559.000000   \n",
       "mean          4.470483                 3.139535                  3.214669   \n",
       "std           2.841469                 3.060067                  2.974877   \n",
       "min           1.000000                 1.000000                  1.000000   \n",
       "25%           2.000000                 1.000000                  1.000000   \n",
       "50%           4.000000                 1.000000                  1.000000   \n",
       "75%           6.000000                 5.000000                  5.000000   \n",
       "max          10.000000                10.000000                 10.000000   \n",
       "\n",
       "       Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "count         559.000000                   559.000000   559.000000   \n",
       "mean            2.831843                     3.216458     3.431127   \n",
       "std             2.879352                     2.225950     3.632070   \n",
       "min             1.000000                     1.000000     0.000000   \n",
       "25%             1.000000                     2.000000     1.000000   \n",
       "50%             1.000000                     2.000000     1.000000   \n",
       "75%             4.000000                     4.000000     5.000000   \n",
       "max            10.000000                    10.000000    10.000000   \n",
       "\n",
       "       Bland Chromatin  Normal Nucleoli    Mitoses  \n",
       "count       559.000000       559.000000  559.00000  \n",
       "mean          3.450805         2.867621    1.60644  \n",
       "std           2.387391         3.060385    1.77569  \n",
       "min           1.000000         1.000000    1.00000  \n",
       "25%           2.000000         1.000000    1.00000  \n",
       "50%           3.000000         1.000000    1.00000  \n",
       "75%           5.000000         4.000000    1.00000  \n",
       "max          10.000000        10.000000   10.00000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "710ba8a6-db95-46b3-8963-6b23202ee3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  3  6  4  8  1  2  7 10  9]\n",
      "[ 1  4  8 10  2  3  7  5  6  9]\n",
      "[ 1  4  8 10  2  3  5  6  7  9]\n",
      "[ 1  5  3  8 10  4  6  2  9  7]\n",
      "[ 2  7  3  1  6  4  5  8 10  9]\n",
      "[ 1 10  2  4  3  9  7  0  5  8  6]\n",
      "[ 3  9  1  2  4  5  7  8  6 10]\n",
      "[ 1  2  7  4  5  3 10  6  9  8]\n",
      "[ 1  5  4  2  3  7 10  8  6]\n"
     ]
    }
   ],
   "source": [
    "for cols in X_train.columns:\n",
    "    print(data[cols].unique())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c4486-7c19-4539-9364-d5e161c4755b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
